{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nova tentativa\n",
    "\n",
    "\n",
    "Mudança na verificação dos contours, porque em alguns casos a countour do tabuleiro não é representado como um quadrilatero. :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contour1\n",
      "Contour2\n",
      "Contour3\n",
      "Contour4\n",
      "Contour5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def print_resized(name, img):\n",
    "    resize_img = cv2.resize(img, (0, 0), fx=0.25, fy=0.25)\n",
    "    cv2.imshow(name, resize_img)\n",
    "\n",
    "\n",
    "\n",
    "def detect_game_board(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(\"Error: Could not load image.\")\n",
    "        return None, None\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0) # to remove some noise\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    print_resized(\"Canny Edges\", edges)\n",
    "\n",
    "    dilated_edges = cv2.dilate(edges, kernel, iterations=1) # dilate to make them more visible\n",
    "\n",
    "    print_resized(\"Canny Dilated\", dilated_edges)\n",
    "\n",
    "\n",
    "    kernel = np.ones((7, 7), np.uint8)  # Larger kernel for better connection\n",
    "    closed = cv2.morphologyEx(dilated_edges, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "\n",
    "    print_resized(\"Closed\", closed)\n",
    "\n",
    "    contours, _ = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    board_contour = None\n",
    "    max_area = 0\n",
    "    i = 0\n",
    "    for contour in contours:\n",
    "        # Get convex hull because it works better\n",
    "\n",
    "        hull = cv2.convexHull(contour)\n",
    "        peri = cv2.arcLength(hull, True)\n",
    "        approx = cv2.approxPolyDP(hull, 0.05 * peri, True)  # Higher tolerance for better board detection\n",
    "        \n",
    "        # If is has 4 sides\n",
    "        if len(approx) == 4:\n",
    "            i += 1\n",
    "            print(\"Contour\" + str(i))\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area > max_area:\n",
    "                max_area = area\n",
    "                board_contour = approx\n",
    "                \n",
    "\n",
    "    if board_contour is None:\n",
    "        print(\"No game board detected.\")\n",
    "        return image, None\n",
    "\n",
    "    corners = board_contour.reshape(4, 2).astype(np.float32) #get the corners of the board\n",
    "    width, height = 500, 500\n",
    "    dst_points = np.array([[0, 0], [width-1, 0], [width-1, height-1], [0, height-1]], dtype=np.float32)\n",
    "    matrix = cv2.getPerspectiveTransform(corners, dst_points)\n",
    "    warped = cv2.warpPerspective(image, matrix, (width, height))\n",
    "\n",
    "    cv2.drawContours(image, [board_contour], -1, (0, 255, 0), 3)\n",
    "    return image, warped\n",
    "\n",
    "\n",
    "# For testing\n",
    "image_path = \"images\\G000_IMG062.jpg\"\n",
    "image_path = \"images\\G000_IMG087.jpg\"\n",
    "image_path = \"images\\G000_IMG102.jpg\"\n",
    "image_path = \"images\\G006_IMG048.jpg\"\n",
    "#image_path = \"images\\G006_IMG086.jpg\"\n",
    "#image_path = \"images\\G006_IMG119.jpg\"\n",
    "#image_path = \"images\\G019_IMG082.jpg\"\n",
    "#image_path = \"images\\G028_IMG015.jpg\" #aqui muito fora ESTE É MUITO COMPLEXO XD\n",
    "#image_path = \"images\\G028_IMG062.jpg\"\n",
    "image_path = \"images\\G028_IMG098.jpg\" #aqui ligeiramente\n",
    "#image_path = \"images\\G028_IMG101.jpg\"\n",
    "#image_path = \"images\\G033_IMG043.jpg\"\n",
    "#image_path = \"images\\G033_IMG075.jpg\"\n",
    "#image_path = \"images\\G033_IMG088.jpg\"\n",
    "#image_path = \"images\\G033_IMG101.jpg\"\n",
    "#image_path = \"images\\G038_IMG074.jpg\"\n",
    "#image_path = \"images\\G038_IMG088.jpg\"\n",
    "#image_path = \"images\\G038_IMG103.jpg\"\n",
    "image_path = \"images\\G038_IMG105.jpg\" #mais para dentro\n",
    "#image_path = \"images\\G041_IMG042.jpg\"\n",
    "#image_path = \"images\\G041_IMG048.jpg\"\n",
    "#image_path = \"images\\G041_IMG088.jpg\"\n",
    "#image_path = \"images\\G041_IMG098.jpg\"\n",
    "#image_path = \"images\\G047_IMG053.jpg\"\n",
    "#image_path = \"images\\G047_IMG068.jpg\"\n",
    "#image_path = \"images\\G047_IMG102.jpg\"\n",
    "image_path = \"images\\G047_IMG107.jpg\" #aqui ligeiramente\n",
    "#image_path = \"images\\G056_IMG017.jpg\"\n",
    "image_path = \"images\\G056_IMG077.jpg\" #aqui ligeiramente\n",
    "image_path = \"images\\G056_IMG097.jpg\" #aqui ligeiramente\n",
    "#image_path = \"images\\G058_IMG044.jpg\"\n",
    "#image_path = \"images\\G058_IMG074.jpg\"\n",
    "#image_path = \"images\\G058_IMG100.jpg\"\n",
    "image_path = \"images\\G061_IMG080.jpg\" #mais para dentro\n",
    "#image_path = \"images\\G061_IMG092.jpg\"\n",
    "#image_path = \"images\\G061_IMG098.jpg\"\n",
    "image_path = \"images\\G072_IMG083.jpg\" #aqui\n",
    "#image_path = \"images\\G072_IMG098.jpg\"\n",
    "#image_path = \"images\\G076_IMG072.jpg\"\n",
    "#image_path = \"images\\G076_IMG089.jpg\"\n",
    "#image_path = \"images\\G076_IMG095.jpg\"\n",
    "#image_path = \"images\\G078_IMG092.jpg\"\n",
    "#image_path = \"images\\G083_IMG073.jpg\"\n",
    "#image_path = \"images\\G083_IMG089.jpg\"\n",
    "image_path = \"images\\G087_IMG093.jpg\" #aqui\n",
    "#image_path = \"images\\G087_IMG099.jpg\"\n",
    "#image_path = \"images\\G091_IMG053.jpg\"\n",
    "#image_path = \"images\\G091_IMG074.jpg\"\n",
    "#image_path = \"images\\G091_IMG102.jpg\"\n",
    "#image_path = \"images\\G099_IMG094.jpg\"\n",
    "\n",
    "\n",
    "\n",
    "img_copy = cv2.imread(image_path)\n",
    "print_resized(\"Original Image\", img_copy)\n",
    "\n",
    "original_with_contour, corrected_board = detect_game_board(image_path)\n",
    "if original_with_contour is not None:\n",
    "    cv2.imshow(\"Original with Contour\", original_with_contour)\n",
    "    if corrected_board is not None:\n",
    "        cv2.imshow(\"Corrected Board\", corrected_board)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ler o cavalinho, (Foi a função que se usou para obter a imagem do cavalinho) Não interessa para a entrega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotated left to 5 degrees\n",
      "Rotated left to 10 degrees\n",
      "Rotated left to 15 degrees\n",
      "Rotated left to 20 degrees\n",
      "Rotated left to 25 degrees\n",
      "Rotated left to 30 degrees\n",
      "Rotated left to 35 degrees\n",
      "Rotated left to 40 degrees\n",
      "Rotated left to 45 degrees\n",
      "Rotated left to 50 degrees\n",
      "Rotated left to 55 degrees\n",
      "Rotated left to 60 degrees\n",
      "Rotated left to 65 degrees\n",
      "Rotated left to 70 degrees\n",
      "Rotated left to 75 degrees\n",
      "Rotated left to 80 degrees\n",
      "Rotated left to 85 degrees\n",
      "Rotated left to 90 degrees\n",
      "Rotated left to 95 degrees\n",
      "Rotated left to 100 degrees\n",
      "Rotated left to 105 degrees\n",
      "Rotated left to 110 degrees\n",
      "Rotated left to 115 degrees\n",
      "Rotated left to 120 degrees\n",
      "Rotated left to 125 degrees\n",
      "Rotated left to 130 degrees\n",
      "Rotated left to 135 degrees\n",
      "Rotated left to 140 degrees\n",
      "Rotated left to 145 degrees\n",
      "Rotated left to 150 degrees\n",
      "Rotated left to 155 degrees\n",
      "Rotated left to 160 degrees\n",
      "Rotated left to 165 degrees\n",
      "Rotated left to 170 degrees\n",
      "Rotated left to 175 degrees\n",
      "Rotated left to 180 degrees\n",
      "Select a region of interest (ROI) and press ENTER when done\n",
      "ROI saved to roi_180deg_2_425_98x73.jpg\n"
     ]
    }
   ],
   "source": [
    "def interactive_image_editor(image_path):\n",
    "    \"\"\"\n",
    "    Interactive image viewer and editor with rotation and ROI selection capabilities.\n",
    "    \n",
    "    Controls:\n",
    "    - 'l': Rotate left (counter-clockwise) by 5 degrees\n",
    "    - 'r': Rotate right (clockwise) by 5 degrees\n",
    "    - 's': Select ROI and save it\n",
    "    - 'q': Quit\n",
    "    \n",
    "    Args:\n",
    "        image_path (str): Path to the image file\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Could not load image from {image_path}\")\n",
    "        return\n",
    "    \n",
    "    img = corrected_board\n",
    "\n",
    "    # Create a window\n",
    "    window_name = \"Interactive Image Editor\"\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    \n",
    "    # Calculate appropriate display size\n",
    "    screen_width = 1280  # Reasonable default screen width\n",
    "    screen_height = 720  # Reasonable default screen height\n",
    "    \n",
    "    img_height, img_width = img.shape[:2]\n",
    "    scale = min(screen_width / img_width, screen_height / img_width * 0.8)\n",
    "    \n",
    "    # Set window size\n",
    "    display_width = int(img_width * scale)\n",
    "    display_height = int(img_height * scale)\n",
    "    cv2.resizeWindow(window_name, display_width, display_height)\n",
    "    \n",
    "    # Keep track of rotation angle\n",
    "    angle = 0\n",
    "    rotation_step = 5  # degrees per key press\n",
    "    \n",
    "    # Make a copy of the original image\n",
    "    current_img = img.copy()\n",
    "    \n",
    "    while True:\n",
    "        # Display the current image\n",
    "        cv2.imshow(window_name, current_img)\n",
    "        \n",
    "        # Wait for key press\n",
    "        key = cv2.waitKey(0) & 0xFF\n",
    "        \n",
    "        # Handle key presses\n",
    "        if key == ord('q'):\n",
    "            # Quit\n",
    "            break\n",
    "            \n",
    "        elif key == ord('l'):\n",
    "            # Rotate left (counter-clockwise)\n",
    "            angle += rotation_step\n",
    "            rows, cols = img.shape[:2]\n",
    "            M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "            current_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "            print(f\"Rotated left to {angle} degrees\")\n",
    "            \n",
    "        elif key == ord('r'):\n",
    "            # Rotate right (clockwise)\n",
    "            angle -= rotation_step\n",
    "            rows, cols = img.shape[:2]\n",
    "            M = cv2.getRotationMatrix2D((cols/2, rows/2), angle, 1)\n",
    "            current_img = cv2.warpAffine(img, M, (cols, rows))\n",
    "            print(f\"Rotated right to {angle} degrees\")\n",
    "            \n",
    "        elif key == ord('s'):\n",
    "            # Enter ROI selection mode\n",
    "            print(\"Select a region of interest (ROI) and press ENTER when done\")\n",
    "            roi = cv2.selectROI(window_name, current_img, fromCenter=False, showCrosshair=True)\n",
    "            \n",
    "            if roi != (0, 0, 0, 0):\n",
    "                # Extract the ROI\n",
    "                x, y, w, h = roi\n",
    "                roi_img = current_img[y:y+h, x:x+w]\n",
    "                \n",
    "                # Save the ROI\n",
    "                output_path = f\"roi_{angle}deg_{x}_{y}_{w}x{h}.jpg\"\n",
    "                cv2.imwrite(output_path, roi_img)\n",
    "                print(f\"ROI saved to {output_path}\")\n",
    "                \n",
    "                # Show the ROI\n",
    "                cv2.imshow(\"Selected ROI\", roi_img)\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Example usage:\n",
    "interactive_image_editor(\"images/G000_IMG062.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver o cavalinho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw rotation angle: 182.71 degrees\n",
      "Quantized rotation angle: 180 degrees\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "img1 = cv2.imread('cavalinhoPequeno.jpg', cv2.IMREAD_GRAYSCALE) \n",
    "#img2 = cv2.imread('images\\G000_IMG102.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "#img2 = cv2.imread('images\\G000_IMG087.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "#img2 = cv2.imread('images\\G000_IMG062.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "#img2 = cv2.imread('images\\G006_IMG048.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "#img2 = corrected_board\n",
    "#img2 = corrected_board\n",
    "\n",
    "\n",
    "img2 = cv2.cvtColor(corrected_board, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Preprocess for SIFT\n",
    "img1 = cv2.equalizeHist(img1)\n",
    "img2 = cv2.equalizeHist(img2)\n",
    "\n",
    "# Initiate SIFT detector\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# Find the keypoints and descriptors with SIFT\n",
    "kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "\n",
    "# Apply FLANN Matcher\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Store all matches (taking the best match from each pair)\n",
    "good = [m for m, n in matches]\n",
    "\n",
    "# Prepare points for homography\n",
    "query_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)  # img1\n",
    "train_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)  # img2\n",
    "\n",
    "# Find homography from query (img1) to train (img2)\n",
    "M, mask = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "# Define corners of the query image\n",
    "h, w = img1.shape[:2]\n",
    "\n",
    "\n",
    "corners = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
    "\n",
    "\n",
    "# Transform corners to train image coordinates\n",
    "transformed_corners = cv2.perspectiveTransform(corners, M)\n",
    "\n",
    "\n",
    "# Create a copy of train image for drawing\n",
    "train_with_box = img2.copy()\n",
    "\n",
    "# Draw lines connecting the transformed corners\n",
    "transformed_corners = np.int32(transformed_corners)\n",
    "cv2.polylines(train_with_box, [transformed_corners], True, (0, 255, 255), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display results\n",
    "cv2.imshow('Query Image', img1)\n",
    "cv2.imshow('Train Image with Object Outline', train_with_box)\n",
    "\n",
    "\n",
    "#To Guarantee angle og 0, 90, 180 or 270 degrees\n",
    "def extract_rotation_from_homography(M):\n",
    "    # Extract rotation angle from homography matrix\n",
    "    a = M[0, 0]\n",
    "    b = M[0, 1]\n",
    "    c = M[1, 0]\n",
    "    d = M[1, 1]\n",
    "    \n",
    "    # Calculate rotation angle\n",
    "    angle_rad = np.arctan2(c, a)\n",
    "    raw_angle_deg = np.degrees(angle_rad)\n",
    "    \n",
    "    # Normalize angle to 0-360 range\n",
    "    raw_angle_deg = raw_angle_deg % 360\n",
    "    if raw_angle_deg < 0:\n",
    "        raw_angle_deg += 360\n",
    "        \n",
    "    # Quantize to 0, 90, 180, or 270 degrees\n",
    "    quantized_angle = round(raw_angle_deg / 90) * 90\n",
    "    if quantized_angle == 360:\n",
    "        quantized_angle = 0\n",
    "        \n",
    "    print(f\"Raw rotation angle: {raw_angle_deg:.2f} degrees\")\n",
    "    print(f\"Quantized rotation angle: {quantized_angle:.0f} degrees\")\n",
    "    return quantized_angle\n",
    "\n",
    "\n",
    "\n",
    "# Extract rotation angle from homography matrix M\n",
    "rotation_angle = extract_rotation_from_homography(M)\n",
    "\n",
    "# Create a pure rotation matrix centered on the image\n",
    "h, w = img2.shape[:2]\n",
    "center = (w // 2, h // 2)\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "\n",
    "# Apply the rotation to the train image\n",
    "rotated_img = cv2.warpAffine(corrected_board, rotation_matrix, (w, h), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "# Display the results\n",
    "cv2.imshow('Original Train Image', img2)\n",
    "cv2.imshow('Rotated Train Image (center fixed)', rotated_img)\n",
    "\n",
    "# Draw crosshair at center point for visualization\n",
    "center_img = img2.copy()\n",
    "cv2.drawMarker(center_img, center, (255, 255, 255), cv2.MARKER_CROSS, 20, 2)\n",
    "cv2.imshow('Center Point', center_img)\n",
    "\n",
    "\n",
    "corrected_board = rotated_img\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try for the hough lines\n",
    "\n",
    "corrected_board2 = corrected_board.copy()\n",
    "\n",
    "cv2.imshow(\"board\", corrected_board)\n",
    "#print_resized(\"Original Image\", corrected_board)\n",
    "\n",
    "#detect lines\n",
    "gray = cv2.cvtColor(corrected_board, cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray, 50, 250, apertureSize=3)\n",
    "\n",
    "#dilate the edges\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "cv2.imshow(\"Canny Edges\", edges)\n",
    "\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 150)  # Threshold 150, adjust as needed\n",
    "\n",
    "# print the lines\n",
    "\n",
    "if lines is not None:\n",
    "    for rho, theta in lines[:, 0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        pt1 = (int(x0 + 1000 * (-b)), int(y0 + 1000 * (a)))\n",
    "        pt2 = (int(x0 - 1000 * (-b)), int(y0 - 1000 * (a)))\n",
    "        cv2.line(corrected_board2, pt1, pt2, (0, 0, 255), 1)\n",
    "\n",
    "cv2.imshow(\"Hough Lines\", corrected_board2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 14 horizontal lines and 8 vertical lines\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Make a copy of the corrected board\n",
    "corrected_board2 = corrected_board.copy()\n",
    "\n",
    "# Display the original board\n",
    "cv2.imshow(\"board\", corrected_board)\n",
    "\n",
    "\n",
    "# Detect lines\n",
    "gray = cv2.cvtColor(corrected_board, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#blur_7 = cv2.GaussianBlur(gray, (7, 7), 0)  # Large kernel\n",
    "\n",
    "#gray = cv2.adaptiveThreshold(blur_7, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "#                                    cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "\n",
    "\n",
    "edges = cv2.Canny(gray, 50, 300, apertureSize=3)\n",
    "\n",
    "# Dilate the edges (optional, helps connect small gaps)\n",
    "\n",
    "\n",
    "# Show the Canny edges\n",
    "cv2.imshow(\"Canny Edges\", edges)\n",
    "\n",
    "# Detect lines using Hough Transform\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 110)  # Threshold 150, adjust as needed\n",
    "\n",
    "# Function to filter lines by minimum distance\n",
    "def filter_lines(lines, min_dist):\n",
    "    if not lines:\n",
    "        return []\n",
    "    filtered = [lines[0]]  # Start with the first line\n",
    "    for rho, theta in lines[1:]:\n",
    "        if abs(rho - filtered[-1][0]) >= min_dist:\n",
    "            filtered.append((rho, theta))\n",
    "    return filtered\n",
    "\n",
    "# Separate horizontal and vertical lines\n",
    "h_lines, v_lines = [], []\n",
    "min_dist = 50  # Minimum distance between lines (adjust based on your image)\n",
    "#min_dist = 0\n",
    "\n",
    "if lines is not None:\n",
    "    for rho, theta in lines[:, 0]:\n",
    "        angle = theta * 180 / np.pi\n",
    "        if 0 <= angle < 10 or 170 <= angle <= 180:  # Horizontal lines\n",
    "            h_lines.append((rho, theta))\n",
    "        elif 80 <= angle <= 100:  # Vertical lines\n",
    "            v_lines.append((rho, theta))\n",
    "\n",
    "    # Sort and filter lines to enforce minimum distance\n",
    "    h_lines = sorted(h_lines, key=lambda x: x[0])\n",
    "    v_lines = sorted(v_lines, key=lambda x: x[0])\n",
    "    h_lines = filter_lines(h_lines, min_dist)[:100]  # Up to 9 horizontal lines for 8x8 grid\n",
    "    v_lines = filter_lines(v_lines, min_dist)[:100]  # Up to 9 vertical lines for 8x8 grid\n",
    "\n",
    "    # Draw horizontal lines (red)\n",
    "    for rho, theta in h_lines:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        pt1 = (int(x0 + 1000 * (-b)), int(y0 + 1000 * (a)))\n",
    "        pt2 = (int(x0 - 1000 * (-b)), int(y0 - 1000 * (a)))\n",
    "        cv2.line(corrected_board2, pt1, pt2, (0, 0, 255), 1)  # Red for horizontal\n",
    "\n",
    "    # Draw vertical lines (green)\n",
    "    for rho, theta in v_lines:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        pt1 = (int(x0 + 1000 * (-b)), int(y0 + 1000 * (a)))\n",
    "        pt2 = (int(x0 - 1000 * (-b)), int(y0 - 1000 * (a)))\n",
    "        cv2.line(corrected_board2, pt1, pt2, (0, 255, 0), 1)  # Green for vertical\n",
    "\n",
    "    print(f\"Detected {len(h_lines)} horizontal lines and {len(v_lines)} vertical lines\")\n",
    "\n",
    "# Show the image with Hough lines\n",
    "cv2.imshow(\"Hough Lines\", corrected_board2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "representar em matriz ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 64 tiles to directory: temp_chess_tiles\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#cut the corrected board by 35 on each side\n",
    "corrected_board_cut = corrected_board[40:460, 40:460]\n",
    "\n",
    "size = round((465-44) / 8)\n",
    "#size = round((460-40) / 8)\n",
    "\n",
    "\n",
    "# Create a temporary directory to save tiles if it doesn't exist\n",
    "temp_dir = \"temp_chess_tiles\"\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "'''\n",
    "#size = 50\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        cv2.rectangle(corrected_board_cut, (i*size, j*size), (i*size+size, j*size+size), (0, 255, 0), 1)\n",
    "'''\n",
    "# Extract and save each tile\n",
    "for j in range(8):\n",
    "    for i in range(8):\n",
    "        # Extract the tile\n",
    "        x1, y1 = i * size, j * size\n",
    "        x2, y2 = x1 + size, y1 + size\n",
    "        \n",
    "        # Get the tile image\n",
    "        tile = corrected_board_cut[y1:y2, x1:x2].copy()\n",
    "        \n",
    "        # Save the tile\n",
    "        tile_filename = f\"{temp_dir}/tile_{j}_{i}.jpg\"\n",
    "        cv2.imwrite(tile_filename, tile)\n",
    "        \n",
    "        # Draw rectangle on the original image for visualization\n",
    "        cv2.rectangle(corrected_board_cut, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "print(f\"Saved 64 tiles to directory: {temp_dir}\")\n",
    "\n",
    "# Display the board with grid overlay\n",
    "cv2.imshow(\"Board with grid\", corrected_board_cut)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_resized_up(name, img):\n",
    "    resize_img = cv2.resize(img, (0, 0), fx=5.0, fy=5.0)\n",
    "    cv2.imshow(name, resize_img)\n",
    "\n",
    "#resize the tile\n",
    "tile = cv2.imread(\"temp_chess_tiles/tile_0_0.jpg\")\n",
    "print_resized_up(\"Tile\", tile)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to try for each tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White pixels: 165, Black pixels: 2644\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "def check_B_in_W(img):\n",
    "    # Display the original tile (assuming print_resized_up is a custom display function)\n",
    "    #print_resized_up(\"Tile\", img)\n",
    "\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Binarize the image (black = 0, white = 255)\n",
    "    _, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "    #print_resized_up(\"Threshold\", thresh)\n",
    "    \n",
    "    # Count black and white pixels\n",
    "    black_pixels = np.sum(thresh == 0)  # Pixels with value 0\n",
    "    white_pixels = np.sum(thresh == 255)  # Pixels with value 255\n",
    "    \n",
    "    # Print the counts for debugging\n",
    "    #print(f\"Black pixels: {black_pixels}, White pixels: {white_pixels}\")\n",
    "    \n",
    "    # Return True if black pixels exceed white pixels\n",
    "    return black_pixels > 650\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_W_in_W(img):\n",
    "    # Display the original tile\n",
    "    #print_resized_up(\"Tile\", img)\n",
    "\n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    #cv2.imshow(\"HSV\", hsv)\n",
    "\n",
    "    # Create a mask:\n",
    "    # - S (saturation) < 82 (low saturation for white/light colors)\n",
    "    # - V (value/brightness) < 101 (darker areas excluded)\n",
    "    # Pixels within this range will be 255 (white), others 0 (black)\n",
    "    upper_bound = (179, 255, 255)    # Minimum H, S, V\n",
    "    lower_bound = (0, 82, 101)  # Maximum H, S, V\n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "    #print_resized_up(\"Mask\", mask)\n",
    "\n",
    "    # Count white pixels (255) and black pixels (0) in the mask\n",
    "    white_pixels = np.sum(mask == 255)\n",
    "    black_pixels = np.sum(mask == 0)\n",
    "    #print(f\"White pixels: {white_pixels}, Black pixels: {black_pixels}\")\n",
    "\n",
    "    # Optional: Display the HSV image again (not modified, so same as before)\n",
    "    #print_resized_up(\"HSV2\", hsv)\n",
    "\n",
    "    # Return True if more white pixels than black (indicating a light area/piece)\n",
    "    return white_pixels > 650\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_W_in_B(img):\n",
    "    # Display the original tile\n",
    "    print_resized_up(\"Tile\", img)\n",
    "\n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imshow(\"HSV\", hsv)\n",
    "\n",
    "    # Create a mask:\n",
    "    # - S (saturation) < 82 (low saturation for white/light colors)\n",
    "    # - V (value/brightness) < 101 (darker areas excluded)\n",
    "    # Pixels within this range will be 255 (white), others 0 (black)\n",
    "    upper_bound = (179, 255, 255)    # Minimum H, S, V\n",
    "    lower_bound = (0, 49, 80)  # Maximum H, S, V\n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "    print_resized_up(\"Mask\", mask)\n",
    "\n",
    "    # Count white pixels (255) and black pixels (0) in the mask\n",
    "    white_pixels = np.sum(mask == 255)\n",
    "    black_pixels = np.sum(mask == 0)\n",
    "    print(f\"White pixels: {white_pixels}, Black pixels: {black_pixels}\")\n",
    "\n",
    "    # Optional: Display the HSV image again (not modified, so same as before)\n",
    "    #print_resized_up(\"HSV2\", hsv)\n",
    "\n",
    "    # Return True if more white pixels than black (indicating a light area/piece)\n",
    "    return white_pixels > 650\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_B_in_B(img):\n",
    "    # Display the original tile\n",
    "    #print_resized_up(\"Tile\", img)\n",
    "\n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    #cv2.imshow(\"HSV\", hsv)\n",
    "\n",
    "    # Create a mask:\n",
    "    # - S (saturation) > 82 (low saturation for white/light colors)\n",
    "    # - V (value/brightness) < 101 (darker areas excluded)\n",
    "    # Pixels within this range will be 255 (white), others 0 (black)\n",
    "    upper_bound = (179, 255, 30)    # Minimum H, S, V\n",
    "    lower_bound = (0, 0, 0)  # Maximum H, S, V\n",
    "    mask = cv2.inRange(hsv, lower_bound, upper_bound)\n",
    "    #print_resized_up(\"Mask\", mask)\n",
    "\n",
    "    # Count white pixels (255) and black pixels (0) in the mask\n",
    "    white_pixels = np.sum(mask == 255)\n",
    "    black_pixels = np.sum(mask == 0)\n",
    "    #print(f\"White pixels: {white_pixels}, Black pixels: {black_pixels}\")\n",
    "\n",
    "    # Optional: Display the HSV image again (not modified, so same as before)\n",
    "    #print_resized_up(\"HSV2\", hsv)\n",
    "\n",
    "    # Return True if more white pixels than black (indicating a light area/piece)\n",
    "    return white_pixels > 650\n",
    "\n",
    "\n",
    "'''\n",
    "tile = cv2.imread(\"temp_chess_tiles/tile_1_4.jpg\")\n",
    "print(check_B_in_W(tile))\n",
    "\n",
    "tile = cv2.imread(\"temp_chess_tiles/tile_3_0.jpg\")\n",
    "print(check_W_in_W(tile))\n",
    "'''\n",
    "\n",
    "\n",
    "tile = cv2.imread(\"temp_chess_tiles/tile_1_5.jpg\")\n",
    "print(check_W_in_B(tile))\n",
    "\n",
    "'''\n",
    "tile = cv2.imread(\"temp_chess_tiles/tile_1_3.jpg\")\n",
    "print(check_B_in_B(tile))\n",
    "'''\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White pixels: 0, Black pixels: 2809\n",
      "Tile 0_1 is a black piece.\n",
      "White pixels: 137, Black pixels: 2672\n",
      "White pixels: 771, Black pixels: 2038\n",
      "Tile 0_4 is a white piece.\n",
      "Tile 0_5 is a black piece.\n",
      "White pixels: 134, Black pixels: 2675\n",
      "Tile 1_0 is a black piece.\n",
      "White pixels: 276, Black pixels: 2533\n",
      "Tile 1_2 is a black piece.\n",
      "White pixels: 251, Black pixels: 2558\n",
      "Tile 1_4 is a black piece.\n",
      "White pixels: 165, Black pixels: 2644\n",
      "Tile 1_6 is a black piece.\n",
      "Tile 1_7 is a black piece.\n",
      "White pixels: 148, Black pixels: 2661\n",
      "Tile 2_1 is a black piece.\n",
      "White pixels: 207, Black pixels: 2602\n",
      "Tile 2_3 is a black piece.\n",
      "White pixels: 218, Black pixels: 2591\n",
      "Tile 2_5 is a black piece.\n",
      "Tile 2_6 is a black piece.\n",
      "Tile 2_7 is a black piece.\n",
      "Tile 3_0 is a black piece.\n",
      "White pixels: 561, Black pixels: 2248\n",
      "Tile 3_2 is a black piece.\n",
      "White pixels: 317, Black pixels: 2492\n",
      "Tile 3_4 is a black piece.\n",
      "White pixels: 314, Black pixels: 2495\n",
      "Tile 3_6 is a white piece.\n",
      "White pixels: 147, Black pixels: 2450\n",
      "White pixels: 954, Black pixels: 1855\n",
      "Tile 4_0 is a white piece.\n",
      "Tile 4_1 is a black piece.\n",
      "White pixels: 345, Black pixels: 2464\n",
      "Tile 4_3 is a black piece.\n",
      "White pixels: 270, Black pixels: 2539\n",
      "Tile 4_5 is a black piece.\n",
      "White pixels: 519, Black pixels: 2290\n",
      "Tile 4_7 is a black piece.\n",
      "Tile 5_0 is a black piece.\n",
      "White pixels: 414, Black pixels: 2395\n",
      "Tile 5_2 is a white piece.\n",
      "White pixels: 259, Black pixels: 2550\n",
      "Tile 5_4 is a black piece.\n",
      "White pixels: 827, Black pixels: 1982\n",
      "Tile 5_5 is a white piece.\n",
      "Tile 5_6 is a black piece.\n",
      "White pixels: 611, Black pixels: 1986\n",
      "White pixels: 116, Black pixels: 2693\n",
      "Tile 6_1 is a black piece.\n",
      "White pixels: 692, Black pixels: 2117\n",
      "Tile 6_2 is a white piece.\n",
      "Tile 6_3 is a black piece.\n",
      "White pixels: 1296, Black pixels: 1513\n",
      "Tile 6_4 is a white piece.\n",
      "Tile 6_5 is a black piece.\n",
      "White pixels: 1879, Black pixels: 930\n",
      "Tile 6_6 is a white piece.\n",
      "Tile 6_7 is a white piece.\n",
      "Tile 7_0 is a black piece.\n",
      "White pixels: 225, Black pixels: 2372\n",
      "Tile 7_2 is a black piece.\n",
      "White pixels: 685, Black pixels: 1912\n",
      "Tile 7_3 is a white piece.\n",
      "Tile 7_4 is a white piece.\n",
      "White pixels: 640, Black pixels: 1957\n",
      "Tile 7_6 is a white piece.\n",
      "White pixels: 951, Black pixels: 1450\n",
      "Tile 7_7 is a white piece.\n",
      "Total black pieces: 27\n",
      "Total white pieces: 13\n",
      "Chessboard Matrix (1 for piece, 0 for empty):\n",
      "[[0 1 0 0 1 1 0 0]\n",
      " [1 0 1 0 1 0 1 1]\n",
      " [0 1 0 1 0 1 1 1]\n",
      " [1 0 1 0 1 0 1 0]\n",
      " [1 1 0 1 0 1 0 1]\n",
      " [1 0 1 0 1 1 1 0]\n",
      " [0 1 1 1 1 1 1 1]\n",
      " [1 0 1 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize counters for black and white pieces\n",
    "blacks = 0\n",
    "whites = 0\n",
    "\n",
    "# Initialize the 8x8 matrix (0 for empty, 1 for piece)\n",
    "chessboard_matrix = np.zeros((8, 8), dtype=int)\n",
    "\n",
    "# Iterate over the 8x8 grid\n",
    "for j in range(8):\n",
    "    for i in range(8):\n",
    "        # Load the tile image\n",
    "        tile = cv2.imread(f\"temp_chess_tiles/tile_{j}_{i}.jpg\")\n",
    "        \n",
    "        if tile is None:\n",
    "            print(f\"Error: Could not load tile_{j}_{i}.jpg\")\n",
    "            continue\n",
    "\n",
    "        # Check if the tile is black or white based on its position\n",
    "        if (j + i) % 2 == 0:  # Black tile\n",
    "            if check_B_in_B(tile):\n",
    "                print(f\"Tile {j}_{i} is a black piece.\")\n",
    "                blacks += 1\n",
    "                chessboard_matrix[j, i] = 1  # Piece present\n",
    "            elif check_W_in_B(tile):\n",
    "                print(f\"Tile {j}_{i} is a white piece.\")\n",
    "                whites += 1\n",
    "                chessboard_matrix[j, i] = 1  # Piece present\n",
    "        else:  # White tile\n",
    "            if check_W_in_W(tile):\n",
    "                print(f\"Tile {j}_{i} is a white piece.\")\n",
    "                whites += 1\n",
    "                chessboard_matrix[j, i] = 1  # Piece present\n",
    "            elif check_B_in_W(tile):\n",
    "                print(f\"Tile {j}_{i} is a black piece.\")\n",
    "                blacks += 1\n",
    "                chessboard_matrix[j, i] = 1  # Piece present\n",
    "\n",
    "# Print the total counts\n",
    "print(f\"Total black pieces: {blacks}\")\n",
    "print(f\"Total white pieces: {whites}\")\n",
    "\n",
    "# Print the matrix\n",
    "print(\"Chessboard Matrix (1 for piece, 0 for empty):\")\n",
    "print(chessboard_matrix)\n",
    "\n",
    "\n",
    "cv2.imshow(\"original\",corrected_board)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper to decide the colour threshholds in hsv (não correr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntile = cv2.imread(\"temp_chess_tiles/tile_1_3.jpg\")\\nif tile is not None:\\n    result = check_W_in_W(tile)\\n    print(f\"White piece detected: {result}\")\\nelse:\\n    print(\"Could not load image\")\\n    \\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\\'\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def hsv_color_picker(image):\n",
    "    # Create a window\n",
    "    cv2.namedWindow('HSV Color Picker')\n",
    "    \n",
    "    # Create trackbars for HSV values\n",
    "    cv2.createTrackbar('H Min', 'HSV Color Picker', 0, 179, nothing)\n",
    "    cv2.createTrackbar('S Min', 'HSV Color Picker', 0, 255, nothing)\n",
    "    cv2.createTrackbar('V Min', 'HSV Color Picker', 0, 255, nothing)\n",
    "    cv2.createTrackbar('H Max', 'HSV Color Picker', 179, 179, nothing)\n",
    "    cv2.createTrackbar('S Max', 'HSV Color Picker', 255, 255, nothing)\n",
    "    cv2.createTrackbar('V Max', 'HSV Color Picker', 255, 255, nothing)\n",
    "    \n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    while True:\n",
    "        # Get current positions of all trackbars\n",
    "        h_min = cv2.getTrackbarPos('H Min', 'HSV Color Picker')\n",
    "        s_min = cv2.getTrackbarPos('S Min', 'HSV Color Picker')\n",
    "        v_min = cv2.getTrackbarPos('V Min', 'HSV Color Picker')\n",
    "        h_max = cv2.getTrackbarPos('H Max', 'HSV Color Picker')\n",
    "        s_max = cv2.getTrackbarPos('S Max', 'HSV Color Picker')\n",
    "        v_max = cv2.getTrackbarPos('V Max', 'HSV Color Picker')\n",
    "        \n",
    "        # Set minimum and maximum HSV values\n",
    "        lower = np.array([h_min, s_min, v_min])\n",
    "        upper = np.array([h_max, s_max, v_max])\n",
    "        \n",
    "        # Create mask\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "        \n",
    "        # Apply mask to original image\n",
    "        result = cv2.bitwise_and(image, image, mask=mask)\n",
    "        \n",
    "        # Show the images\n",
    "        # Stack images horizontally for comparison\n",
    "        stacked = np.hstack((image, result))\n",
    "        cv2.imshow('HSV Color Picker', stacked)\n",
    "        \n",
    "        # Print current HSV values (useful for debugging)\n",
    "        print(f\"H_min: {h_min}, S_min: {s_min}, V_min: {v_min}, H_max: {h_max}, S_max: {s_max}, V_max: {v_max}\", end=\"\\r\")\n",
    "        \n",
    "        # Break loop on ESC key\n",
    "        k = cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:  # ESC key\n",
    "            break\n",
    "    \n",
    "    # Print final values for easy copy-paste\n",
    "    print(f\"\\nFinal values:\")\n",
    "    print(f\"lower = np.array([{h_min}, {s_min}, {v_min}])\")\n",
    "    print(f\"upper = np.array([{h_max}, {s_max}, {v_max}])\")\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "    return lower, upper\n",
    "\n",
    "# Modified check_W_in_W function to use HSV color picker\n",
    "def check_W_in_W(img):\n",
    "    print_resized_up(\"Tile\", img)\n",
    "    \n",
    "    # Use the HSV color picker to find the right thresholds\n",
    "    lower, upper = hsv_color_picker(img)\n",
    "    \n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Create mask with the selected thresholds\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    \n",
    "    # Apply mask\n",
    "    result = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    print_resized_up(\"HSV Filtered\", result)\n",
    "    \n",
    "    # Count non-zero pixels in the mask\n",
    "    white_piece_pixels = cv2.countNonZero(mask)\n",
    "    print(f\"White piece pixels: {white_piece_pixels}\")\n",
    "    \n",
    "    return white_piece_pixels > 100  # Adjust threshold as needed\n",
    "\n",
    "# Test the function\n",
    "'''\n",
    "tile = cv2.imread(\"temp_chess_tiles/tile_1_3.jpg\")\n",
    "if tile is not None:\n",
    "    result = check_W_in_W(tile)\n",
    "    print(f\"White piece detected: {result}\")\n",
    "else:\n",
    "    print(\"Could not load image\")\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport cv2\\nimport numpy as np\\n\\n# Load and preprocess the image\\nimage = corrected_board  # Assuming corrected_board is already defined\\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\\ngray = cv2.GaussianBlur(gray, (5, 5), 0)\\nedges = cv2.Canny(gray, 50, 150, apertureSize=3)\\n\\n# Detect lines using Hough Transform\\nlines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\\n\\n# Separate horizontal and vertical lines\\nh_lines, v_lines = [], []\\nif lines is not None:\\n    for rho, theta in lines[:, 0]:\\n        angle = theta * 180 / np.pi\\n        if 0 <= angle < 10 or 170 <= angle <= 180:  # Horizontal lines\\n            h_lines.append((rho, theta))\\n        elif 80 <= angle <= 100:  # Vertical lines\\n            v_lines.append((rho, theta))\\n\\n# Function to filter lines by minimum distance\\ndef filter_lines(lines, min_distance):\\n    if not lines:\\n        return []\\n    filtered = [lines[0]]  # Start with the first line\\n    for rho, theta in lines[1:]:\\n        # Check if the current rho is far enough from the last filtered line\\n        if abs(rho - filtered[-1][0]) >= min_distance:\\n            filtered.append((rho, theta))\\n    return filtered\\n\\n# Sort and filter lines (e.g., min_distance = 20 pixels, adjust as needed)\\nmin_distance = 30  # Adjust this value based on your image resolution\\nh_lines = sorted(h_lines, key=lambda x: x[0])\\nv_lines = sorted(v_lines, key=lambda x: x[0])\\nh_lines = filter_lines(h_lines, min_distance)[:9]  # Get up to 9 horizontal lines\\nv_lines = filter_lines(v_lines, min_distance)[:9]  # Get up to 9 vertical lines\\n\\n# Check if we have enough lines\\nif len(h_lines) < 9 or len(v_lines) < 9:\\n    print(f\"Warning: Found only {len(h_lines)} horizontal and {len(v_lines)} vertical lines.\")\\nelse:\\n    print(f\"Found {len(h_lines)} horizontal and {len(v_lines)} vertical lines.\")\\n\\n# Create the 8x8 matrix\\nchessboard_matrix = np.zeros((8, 8), dtype=int)\\n\\n# Draw the lines on the image\\nfor rho, theta in h_lines:\\n    a, b = np.cos(theta), np.sin(theta)\\n    x0, y0 = a * rho, b * rho\\n    x1, y1 = int(x0 + 1000 * (-b)), int(y0 + 1000 * (a))\\n    x2, y2 = int(x0 - 1000 * (-b)), int(y0 - 1000 * (a))\\n    cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red for horizontal\\n\\nfor rho, theta in v_lines:\\n    a, b = np.cos(theta), np.sin(theta)\\n    x0, y0 = a * rho, b * rho\\n    x1, y1 = int(x0 + 1000 * (-b)), int(y0 + 1000 * (a))\\n    x2, y2 = int(x0 - 1000 * (-b)), int(y0 - 1000 * (a))\\n    cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green for vertical\\n\\n# Display the image\\ncv2.imshow(\\'Detected Lines\\', image)\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\\n\\n# Optional: Print the matrix (you can populate it later)\\nprint(\"Chessboard Matrix (placeholder):\")\\nprint(chessboard_matrix)\\'\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = corrected_board  # Assuming corrected_board is already defined\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "\n",
    "# Detect lines using Hough Transform\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)\n",
    "\n",
    "# Separate horizontal and vertical lines\n",
    "h_lines, v_lines = [], []\n",
    "if lines is not None:\n",
    "    for rho, theta in lines[:, 0]:\n",
    "        angle = theta * 180 / np.pi\n",
    "        if 0 <= angle < 10 or 170 <= angle <= 180:  # Horizontal lines\n",
    "            h_lines.append((rho, theta))\n",
    "        elif 80 <= angle <= 100:  # Vertical lines\n",
    "            v_lines.append((rho, theta))\n",
    "\n",
    "# Function to filter lines by minimum distance\n",
    "def filter_lines(lines, min_distance):\n",
    "    if not lines:\n",
    "        return []\n",
    "    filtered = [lines[0]]  # Start with the first line\n",
    "    for rho, theta in lines[1:]:\n",
    "        # Check if the current rho is far enough from the last filtered line\n",
    "        if abs(rho - filtered[-1][0]) >= min_distance:\n",
    "            filtered.append((rho, theta))\n",
    "    return filtered\n",
    "\n",
    "# Sort and filter lines (e.g., min_distance = 20 pixels, adjust as needed)\n",
    "min_distance = 30  # Adjust this value based on your image resolution\n",
    "h_lines = sorted(h_lines, key=lambda x: x[0])\n",
    "v_lines = sorted(v_lines, key=lambda x: x[0])\n",
    "h_lines = filter_lines(h_lines, min_distance)[:9]  # Get up to 9 horizontal lines\n",
    "v_lines = filter_lines(v_lines, min_distance)[:9]  # Get up to 9 vertical lines\n",
    "\n",
    "# Check if we have enough lines\n",
    "if len(h_lines) < 9 or len(v_lines) < 9:\n",
    "    print(f\"Warning: Found only {len(h_lines)} horizontal and {len(v_lines)} vertical lines.\")\n",
    "else:\n",
    "    print(f\"Found {len(h_lines)} horizontal and {len(v_lines)} vertical lines.\")\n",
    "\n",
    "# Create the 8x8 matrix\n",
    "chessboard_matrix = np.zeros((8, 8), dtype=int)\n",
    "\n",
    "# Draw the lines on the image\n",
    "for rho, theta in h_lines:\n",
    "    a, b = np.cos(theta), np.sin(theta)\n",
    "    x0, y0 = a * rho, b * rho\n",
    "    x1, y1 = int(x0 + 1000 * (-b)), int(y0 + 1000 * (a))\n",
    "    x2, y2 = int(x0 - 1000 * (-b)), int(y0 - 1000 * (a))\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red for horizontal\n",
    "\n",
    "for rho, theta in v_lines:\n",
    "    a, b = np.cos(theta), np.sin(theta)\n",
    "    x0, y0 = a * rho, b * rho\n",
    "    x1, y1 = int(x0 + 1000 * (-b)), int(y0 + 1000 * (a))\n",
    "    x2, y2 = int(x0 - 1000 * (-b)), int(y0 - 1000 * (a))\n",
    "    cv2.line(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green for vertical\n",
    "\n",
    "# Display the image\n",
    "cv2.imshow('Detected Lines', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Optional: Print the matrix (you can populate it later)\n",
    "print(\"Chessboard Matrix (placeholder):\")\n",
    "print(chessboard_matrix)'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n#find the corners\\n\\ncorrected_board2 = corrected_board.copy()\\n\\ngray = cv2.cvtColor(corrected_board2, cv2.COLOR_BGR2GRAY)\\n\\ncorners = cv2.goodFeaturesToTrack(gray, 130, 0.05, 10)\\ncorners = np.intp(corners)\\n\\nfor corner in corners:\\n    x, y = corner.ravel()\\n    cv2.circle(corrected_board2, (x, y), 3, 255, -1)\\n\\ncv2.imshow(\"Corners\", corrected_board2)\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\\n\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "\n",
    "#find the corners\n",
    "\n",
    "corrected_board2 = corrected_board.copy()\n",
    "\n",
    "gray = cv2.cvtColor(corrected_board2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "corners = cv2.goodFeaturesToTrack(gray, 130, 0.05, 10)\n",
    "corners = np.intp(corners)\n",
    "\n",
    "for corner in corners:\n",
    "    x, y = corner.ravel()\n",
    "    cv2.circle(corrected_board2, (x, y), 3, 255, -1)\n",
    "\n",
    "cv2.imshow(\"Corners\", corrected_board2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
